"""
YOLOè½¦è¾†å’Œè¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿ
ä½¿ç”¨YOLOv8æ£€æµ‹è§†é¢‘ä¸­çš„è½¦è¾†å’Œè¡Œäººï¼Œå¹¶å®ç°ç›®æ ‡è·Ÿè¸ªåŠŸèƒ½
ä½œè€…ï¼šClaude Code Assistant
ç‰ˆæœ¬ï¼š2.0 (ä¼˜åŒ–ç‰ˆ)
"""

import cv2
import numpy as np
from ultralytics import YOLO
import torch
from collections import deque
import time
import sys
import os
import warnings
from PIL import Image, ImageDraw, ImageFont

# è§£å†³Windowså¹³å°ä¸­æ–‡ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import locale
    import codecs
    # è®¾ç½®æ§åˆ¶å°ç¼–ç 
    try:
        # å°è¯•è®¾ç½®UTF-8ç¼–ç 
        sys.stdout.reconfigure(encoding='utf-8', errors='ignore')
        sys.stderr.reconfigure(encoding='utf-8', errors='ignore')
        # è®¾ç½®Windowsæ§åˆ¶å°ä»£ç é¡µä¸ºUTF-8
        os.system('chcp 65001 >nul 2>&1')
    except:
        # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ç¼–ç 
        try:
            locale.setlocale(locale.LC_ALL, 'Chinese_Simplified.936')
            sys.stdout.reconfigure(encoding='gbk', errors='ignore')
            sys.stderr.reconfigure(encoding='gbk', errors='ignore')
        except:
            # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
            sys.stdout.reconfigure(encoding='utf-8', errors='ignore')
            sys.stderr.reconfigure(encoding='utf-8', errors='ignore')

# ä¿®å¤PyTorch 2.6æƒé‡åŠ è½½é—®é¢˜
import torch.serialization
try:
    if hasattr(torch.serialization, 'add_safe_globals'):
        torch.serialization.add_safe_globals(['ultralytics.nn.tasks.DetectionModel'])
except:
    pass

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=UserWarning)


def put_chinese_text(img, text, position, font_size=20, color=(255, 255, 255)):
    """
    åœ¨OpenCVå›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬

    Args:
        img: OpenCVå›¾åƒ
        text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
        position: ä½ç½® (x, y)
        font_size: å­—ä½“å¤§å°
        color: é¢œè‰² (B, G, R)

    Returns:
        å¤„ç†åçš„å›¾åƒ
    """
    try:
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)

        # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
        font_paths = [
            "C:/Windows/Fonts/msyh.ttc",        # å¾®è½¯é›…é»‘
            "C:/Windows/Fonts/simhei.ttf",      # é»‘ä½“
            "C:/Windows/Fonts/simsun.ttc",      # å®‹ä½“
            "C:/Windows/Fonts/arial.ttf"        # Arial (å¤‡é€‰)
        ]

        font = None
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue

        if font is None:
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
            font = ImageFont.load_default()

        # ç»˜åˆ¶æ–‡æœ¬
        draw.text(position, text, font=font, fill=color)

        # è½¬æ¢å›OpenCVæ ¼å¼
        img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

    except Exception as e:
        # å¦‚æœPILæ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°OpenCVæ–¹æ³•ï¼ˆæ˜¾ç¤ºè‹±æ–‡ï¼‰
        # è‹±æ–‡æ˜ å°„
        english_map = {
            "è¡Œäºº": "Person", "æ±½è½¦": "Car", "å¡è½¦": "Truck",
            "å…¬äº¤è½¦": "Bus", "æ‘©æ‰˜è½¦": "Motorcycle", "è‡ªè¡Œè½¦": "Bicycle",
            "å¸§æ•°:": "Frame:", "è¡Œäººæ•°:": "People:", "è½¦è¾†æ•°:": "Vehicles:",
            "FPS:": "FPS:", "ID:": "ID:"
        }

        # å°†ä¸­æ–‡è½¬æ¢ä¸ºè‹±æ–‡
        english_text = text
        for chinese, english in english_map.items():
            english_text = english_text.replace(chinese, english)

        # ä½¿ç”¨OpenCVç»˜åˆ¶è‹±æ–‡
        cv2.putText(img, english_text, position, cv2.FONT_HERSHEY_SIMPLEX,
                   font_size / 25, color, 2)

    return img


def create_english_labels():
    """åˆ›å»ºè‹±æ–‡æ ‡ç­¾æ˜ å°„"""
    return {
        'person': 'Person',
        'car': 'Car',
        'truck': 'Truck',
        'bus': 'Bus',
        'motorcycle': 'Motorcycle',
        'bicycle': 'Bicycle'
    }


class ObjectTracker:
    """
    ç›®æ ‡è·Ÿè¸ªå™¨ç±»
    ä½¿ç”¨è´¨å¿ƒè·ç¦»ç®—æ³•è¿›è¡Œå¤šç›®æ ‡è·Ÿè¸ª
    """

    def __init__(self, max_disappeared=10, max_distance=50):
        """
        åˆå§‹åŒ–è·Ÿè¸ªå™¨

        Args:
            max_disappeared (int): ç›®æ ‡æ¶ˆå¤±æœ€å¤§å¸§æ•°ï¼Œè¶…è¿‡åˆ™åˆ é™¤è·Ÿè¸ª
            max_distance (int): åŒ¹é…æœ€å¤§è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        """
        self.next_object_id = 0  # ä¸‹ä¸€ä¸ªç›®æ ‡ID
        self.objects = {}         # å­˜å‚¨æ‰€æœ‰è·Ÿè¸ªç›®æ ‡
        self.disappeared = {}     # å­˜å‚¨ç›®æ ‡æ¶ˆå¤±è®¡æ•°
        self.max_disappeared = max_disappeared
        self.max_distance = max_distance

    def register(self, centroid):
        """
        æ³¨å†Œæ–°çš„è·Ÿè¸ªç›®æ ‡

        Args:
            centroid (tuple): ç›®æ ‡è´¨å¿ƒåæ ‡ (x, y)
        """
        self.objects[self.next_object_id] = {
            'centroid': centroid,     # è´¨å¿ƒä½ç½®
            'class_id': None,         # ç±»åˆ«ID
            'class_name': None,       # ç±»åˆ«åç§°
            'bbox': None,            # è¾¹ç•Œæ¡†åæ ‡
            'trajectory': deque(maxlen=30)  # è½¨è¿¹å†å²ï¼ˆæœ€è¿‘30ä¸ªä½ç½®ï¼‰
        }
        self.disappeared[self.next_object_id] = 0
        self.next_object_id += 1

    def deregister(self, object_id):
        """
        åˆ é™¤è·Ÿè¸ªç›®æ ‡

        Args:
            object_id (int): è¦åˆ é™¤çš„ç›®æ ‡ID
        """
        del self.objects[object_id]
        del self.disappeared[object_id]

    def update(self, detections):
        """
        æ›´æ–°è·Ÿè¸ªå™¨çŠ¶æ€

        Args:
            detections (list): å½“å‰å¸§æ£€æµ‹ç»“æœåˆ—è¡¨

        Returns:
            dict: æ›´æ–°åçš„è·Ÿè¸ªç›®æ ‡å­—å…¸
        """
        # å¦‚æœæ²¡æœ‰æ£€æµ‹ç»“æœï¼Œæ›´æ–°æ‰€æœ‰ç›®æ ‡çš„æ¶ˆå¤±è®¡æ•°
        if len(detections) == 0:
            for object_id in list(self.disappeared.keys()):
                self.disappeared[object_id] += 1
                # å¦‚æœç›®æ ‡æ¶ˆå¤±æ—¶é—´è¿‡é•¿ï¼Œåˆ é™¤è·Ÿè¸ª
                if self.disappeared[object_id] > self.max_disappeared:
                    self.deregister(object_id)
            return self.objects

        # è®¡ç®—æ‰€æœ‰æ£€æµ‹ç»“æœçš„è´¨å¿ƒåæ ‡
        input_centroids = np.zeros((len(detections), 2), dtype="int")
        for i, detection in enumerate(detections):
            x, y, w, h = detection['bbox']
            cx = int(x + w / 2.0)  # è´¨å¿ƒxåæ ‡
            cy = int(y + h / 2.0)  # è´¨å¿ƒyåæ ‡
            input_centroids[i] = (cx, cy)

        # å¦‚æœå½“å‰æ²¡æœ‰è·Ÿè¸ªç›®æ ‡ï¼Œä¸ºæ¯ä¸ªæ£€æµ‹ç»“æœæ³¨å†Œæ–°ç›®æ ‡
        if len(self.objects) == 0:
            for i in range(len(detections)):
                self.register(input_centroids[i])
                obj_id = self.next_object_id - 1
                self.objects[obj_id]['class_id'] = detections[i]['class_id']
                self.objects[obj_id]['class_name'] = detections[i]['class_name']
                self.objects[obj_id]['bbox'] = detections[i]['bbox']
                self.objects[obj_id]['trajectory'].append(input_centroids[i])
        else:
            # è®¡ç®—ç°æœ‰ç›®æ ‡å’Œæ£€æµ‹ç»“æœçš„è·ç¦»çŸ©é˜µ
            object_centroids = np.array([obj['centroid'] for obj in self.objects.values()])
            object_ids = list(self.objects.keys())
            D = np.linalg.norm(object_centroids[:, np.newaxis] - input_centroids[np.newaxis, :], axis=2)

            # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡Œæœ€ä¼˜åŒ¹é…
            rows = D.min(axis=1).argsort()  # æŒ‰æœ€å°è·ç¦»æ’åº
            cols = D.argmin(axis=1)[rows]   # å¯¹åº”çš„æ£€æµ‹ç»“æœç´¢å¼•

            used_row_idxs = set()  # å·²ä½¿ç”¨çš„ç°æœ‰ç›®æ ‡ç´¢å¼•
            used_col_idxs = set()  # å·²ä½¿ç”¨çš„æ£€æµ‹ç»“æœç´¢å¼•

            # åŒ¹é…ç›®æ ‡å’Œæ£€æµ‹ç»“æœ
            for (row, col) in zip(rows, cols):
                if row in used_row_idxs or col in used_col_idxs:
                    continue  # é¿å…é‡å¤åŒ¹é…

                if D[row, col] > self.max_distance:
                    continue  # è·ç¦»è¿‡å¤§ï¼Œä¸åŒ¹é…

                # æ›´æ–°åŒ¹é…ç›®æ ‡çš„ä¿¡æ¯
                if row < len(object_ids):  # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                    object_id = object_ids[row]
                    self.objects[object_id]['centroid'] = input_centroids[col]
                    self.objects[object_id]['bbox'] = detections[col]['bbox']
                    self.objects[object_id]['trajectory'].append(input_centroids[col])
                    self.disappeared[object_id] = 0

                    used_row_idxs.add(row)
                    used_col_idxs.add(col)

            # å¤„ç†æœªåŒ¹é…çš„ç°æœ‰ç›®æ ‡ï¼ˆå¯èƒ½æ¶ˆå¤±ï¼‰
            unused_row_idxs = set(range(0, D.shape[0])).difference(used_row_idxs)
            unused_col_idxs = set(range(0, D.shape[1])).difference(used_col_idxs)

            # å¦‚æœç°æœ‰ç›®æ ‡å¤šäºæ£€æµ‹ç»“æœï¼Œæ›´æ–°æ¶ˆå¤±è®¡æ•°
            if D.shape[0] >= D.shape[1]:
                for row in unused_row_idxs:
                    if row < len(object_ids):  # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                        object_id = object_ids[row]
                        self.disappeared[object_id] += 1
                        if self.disappeared[object_id] > self.max_disappeared:
                            self.deregister(object_id)
            else:
                # å¦‚æœæ£€æµ‹ç»“æœå¤šäºç°æœ‰ç›®æ ‡ï¼Œæ³¨å†Œæ–°ç›®æ ‡
                for col in unused_col_idxs:
                    self.register(input_centroids[col])
                    obj_id = self.next_object_id - 1
                    self.objects[obj_id]['class_id'] = detections[col]['class_id']
                    self.objects[obj_id]['class_name'] = detections[col]['class_name']
                    self.objects[obj_id]['bbox'] = detections[col]['bbox']
                    self.objects[obj_id]['trajectory'].append(input_centroids[col])

        return self.objects


class YOLODetector:
    """
    YOLOæ£€æµ‹å™¨ç±»
    å°è£…YOLOv8æ£€æµ‹åŠŸèƒ½ï¼Œä¸“é—¨ç”¨äºè½¦è¾†å’Œè¡Œäººæ£€æµ‹
    """

    def __init__(self, model_path="yolov8l.pt"):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹å™¨

        Args:
            model_path (str): YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        print(f"æ­£åœ¨åŠ è½½YOLOæ¨¡å‹: {model_path}")

        # ä¿å­˜åŸå§‹çš„torch.loadå‡½æ•°
        original_torch_load = torch.load

        # åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬çš„torch.loadæ¥å¤„ç†weights_onlyé—®é¢˜
        def patched_torch_load(f, *args, **kwargs):
            if 'weights_only' not in kwargs:
                kwargs['weights_only'] = False
            return original_torch_load(f, *args, **kwargs)

        # è®¾ç½®å®‰å…¨å…¨å±€å˜é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(torch.serialization, 'add_safe_globals'):
            try:
                torch.serialization.add_safe_globals(['ultralytics.nn.tasks.DetectionModel'])
            except:
                pass

        try:
            # åº”ç”¨è¡¥ä¸
            torch.load = patched_torch_load
            self.model = YOLO(model_path)
        except Exception as e:
            print(f"ç›´æ¥åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            # å°è¯•å¤‡é€‰æ–¹æ¡ˆ - è®¾ç½®ç¯å¢ƒå˜é‡å¹¶é‡è¯•
            import os
            original_weights_only = os.environ.get('PYTORCH_WEIGHTS_ONLY', '1')
            os.environ['PYTORCH_WEIGHTS_ONLY'] = '0'
            try:
                self.model = YOLO(model_path)
                print("é€šè¿‡ç¯å¢ƒå˜é‡å˜é€šæ–¹æ¡ˆåŠ è½½æ¨¡å‹æˆåŠŸ")
            except Exception as e2:
                print(f"å¤‡é€‰åŠ è½½å¤±è´¥: {e2}")
                raise e2
            finally:
                os.environ['PYTORCH_WEIGHTS_ONLY'] = original_weights_only
        finally:
            # æ¢å¤åŸå§‹torch.load
            torch.load = original_torch_load

        # è·å–æ¨¡å‹ç±»åˆ«åç§°
        self.class_names = self.model.names
        # å®šä¹‰è¦æ£€æµ‹çš„ç›®æ ‡ç±»åˆ«ï¼ˆè½¦è¾†å’Œè¡Œäººç›¸å…³ï¼‰
        self.target_classes = ['person', 'car', 'truck', 'bus', 'motorcycle', 'bicycle']
        # åˆå§‹åŒ–è·Ÿè¸ªå™¨
        self.tracker = ObjectTracker()
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")

        # å®šä¹‰ä¸åŒç±»åˆ«çš„é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰
        self.colors = {
            'person': (0, 255, 0),      # ç»¿è‰² - è¡Œäºº
            'car': (0, 0, 255),         # çº¢è‰² - æ±½è½¦
            'truck': (255, 0, 0),       # è“è‰² - å¡è½¦
            'bus': (255, 255, 0),       # é’è‰² - å…¬äº¤è½¦
            'motorcycle': (255, 0, 255), # ç´«è‰² - æ‘©æ‰˜è½¦
            'bicycle': (0, 255, 255)    # é»„è‰² - è‡ªè¡Œè½¦
        }

    def detect(self, frame, conf_threshold=0.5):
        """
        åœ¨å›¾åƒå¸§ä¸­æ£€æµ‹ç›®æ ‡

        Args:
            frame (numpy.ndarray): è¾“å…¥å›¾åƒå¸§
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            list: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«bboxã€confidenceã€class_idã€class_name
        """
        # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹
        results = self.model(frame, conf=conf_threshold)
        detections = []

        # å¤„ç†æ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = box.conf[0].cpu().numpy()
                    class_id = int(box.cls[0].cpu().numpy())
                    class_name = self.class_names[class_id]

                    # åªæ£€æµ‹ç›®æ ‡ç±»åˆ«
                    if class_name in self.target_classes:
                        bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]
                        detection = {
                            'bbox': bbox,
                            'confidence': confidence,
                            'class_id': class_id,
                            'class_name': class_name
                        }
                        detections.append(detection)

        return detections

    def draw_detections(self, frame, tracked_objects):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè·Ÿè¸ªä¿¡æ¯

        Args:
            frame (numpy.ndarray): è¾“å…¥å›¾åƒå¸§
            tracked_objects (dict): è·Ÿè¸ªç›®æ ‡å­—å…¸

        Returns:
            numpy.ndarray: ç»˜åˆ¶åçš„å›¾åƒå¸§
        """
        for object_id, obj_data in tracked_objects.items():
            bbox = obj_data['bbox']
            class_name = obj_data['class_name']
            trajectory = obj_data['trajectory']

            if bbox is not None:
                x, y, w, h = bbox

                # è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²
                color = self.colors.get(class_name, (255, 255, 255))

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)

                # ç»˜åˆ¶æ ‡ç­¾
                if class_name == 'person':
                    label_text = f"ID: {object_id} è¡Œäºº"
                elif class_name == 'car':
                    label_text = f"ID: {object_id} æ±½è½¦"
                elif class_name == 'truck':
                    label_text = f"ID: {object_id} å¡è½¦"
                elif class_name == 'bus':
                    label_text = f"ID: {object_id} å…¬äº¤è½¦"
                elif class_name == 'motorcycle':
                    label_text = f"ID: {object_id} æ‘©æ‰˜è½¦"
                elif class_name == 'bicycle':
                    label_text = f"ID: {object_id} è‡ªè¡Œè½¦"
                else:
                    label_text = f"ID: {object_id} {class_name}"

                # ç»˜åˆ¶èƒŒæ™¯çŸ©å½¢
                cv2.rectangle(frame, (x, y - 30), (x + 150, y), color, -1)

                # ä½¿ç”¨ä¸­æ–‡æ–‡æœ¬ç»˜åˆ¶å‡½æ•°
                frame = put_chinese_text(frame, label_text, (x, y - 5), 16, (255, 255, 255))

                # ç»˜åˆ¶è½¨è¿¹ï¼ˆå¦‚æœæœ‰å†å²ä½ç½®ï¼‰- å·²ç¦ç”¨
                # if len(trajectory) > 1:
                #     points = np.array(list(trajectory), dtype=np.int32)
                #     cv2.polylines(frame, [points], False, color, 2)

        return frame


class VideoProcessor:
    """
    è§†é¢‘å¤„ç†å™¨ç±»
    åè°ƒæ£€æµ‹å’Œè·Ÿè¸ªåŠŸèƒ½ï¼Œå¤„ç†è§†é¢‘è¾“å…¥å’Œè¾“å‡º
    """

    def __init__(self, model_path="yolov8l.pt"):
        """
        åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨

        Args:
            model_path (str): YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        self.detector = YOLODetector(model_path)

    def process_video(self, video_source, output_path=None, show_display=True):
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶æˆ–æ‘„åƒå¤´è¾“å…¥

        Args:
            video_source: è§†é¢‘æºï¼ˆæ–‡ä»¶è·¯å¾„æˆ–æ‘„åƒå¤´ç´¢å¼•ï¼‰
            output_path (str): è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„
            show_display (bool): æ˜¯å¦æ˜¾ç¤ºå¤„ç†ç»“æœ
        """
        # æ‰“å¼€è§†é¢‘æº
        cap = cv2.VideoCapture(video_source)

        if not cap.isOpened():
            print(f"é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
            return

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        # è®¾ç½®è¾“å‡ºè§†é¢‘
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        else:
            out = None

        print(f"æ­£åœ¨å¤„ç†è§†é¢‘ - å¸§ç‡: {fps}, åˆ†è¾¨ç‡: {width}x{height}")
        print("æŒ‰ 'q' é€€å‡º, æŒ‰ 's' ä¿å­˜å½“å‰å¸§")

        frame_count = 0
        start_time = time.time()

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1

            # æ£€æµ‹ç›®æ ‡
            detections = self.detector.detect(frame)

            # æ›´æ–°è·Ÿè¸ªå™¨
            tracked_objects = self.detector.tracker.update(detections)

            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            frame = self.detector.draw_detections(frame, tracked_objects)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            person_count = sum(1 for obj in tracked_objects.values() if obj['class_name'] == 'person')
            vehicle_count = sum(1 for obj in tracked_objects.values() if obj['class_name'] != 'person')

            # æ˜¾ç¤ºä¸­æ–‡ç»Ÿè®¡ä¿¡æ¯
            frame = put_chinese_text(frame, f"å¸§æ•°: {frame_count}", (10, 30), 20, (255, 255, 255))
            frame = put_chinese_text(frame, f"è¡Œäººæ•°: {person_count}", (10, 60), 20, (255, 255, 255))
            frame = put_chinese_text(frame, f"è½¦è¾†æ•°: {vehicle_count}", (10, 90), 20, (255, 255, 255))

            # è®¡ç®—å¹¶æ˜¾ç¤ºFPS
            if frame_count % 30 == 0:
                elapsed_time = time.time() - start_time
                current_fps = frame_count / elapsed_time
                frame = put_chinese_text(frame, f"FPS: {current_fps:.2f}", (10, 120), 20, (255, 255, 255))

            # æ˜¾ç¤ºæˆ–ä¿å­˜ç»“æœ
            if show_display:
                cv2.imshow('YOLO Vehicle and Pedestrian Detection & Tracking', frame)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    cv2.imwrite(f'æ£€æµ‹ç»“æœ_{frame_count}.jpg', frame)
                    print(f"å·²ä¿å­˜ç¬¬ {frame_count} å¸§")

            if out:
                out.write(frame)

        # æ¸…ç†èµ„æº
        cap.release()
        if out:
            out.release()
        cv2.destroyAllWindows()

        # è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time
        print(f"\nå¤„ç†å®Œæˆ!")
        print(f"{'='*50}")
        print(f"æ€§èƒ½ç»Ÿè®¡")
        print(f"{'='*50}")
        print(f"æ€»å¸§æ•°: {frame_count}")
        print(f"å¹³å‡FPS: {avg_fps:.2f}")
        print(f"å¤„ç†æ—¶é—´: {total_time:.2f} ç§’")
        print(f"è§†é¢‘æ—¶é•¿: {frame_count/max(fps, 1):.2f} ç§’")

        # æ€§èƒ½å»ºè®®
        if avg_fps < 15:
            print(f"\nâš ï¸  æ£€æµ‹åˆ°æ€§èƒ½è¾ƒä½!")
            print("å»ºè®®:")
            print("- å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (yolov8n.pt æˆ– yolov8s.pt)")
            print("- é™ä½è§†é¢‘åˆ†è¾¨ç‡")
            print("- å…³é—­å…¶ä»–åº”ç”¨ç¨‹åº")
        elif avg_fps > 30:
            print(f"\nâœ… æ€§èƒ½ä¼˜ç§€!")
            print("æ‚¨å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹è·å¾—æ›´é«˜ç²¾åº¦:")
            print("- å°è¯• yolov8x.pt è·å¾—æ›´é«˜ç²¾åº¦")
        else:
            print(f"\nğŸ‘ æ€§èƒ½è‰¯å¥½")
            print("å½“å‰è®¾ç½®æä¾›äº†å¾ˆå¥½çš„å¹³è¡¡")

        print(f"\nè¾“å‡ºæ–‡ä»¶: {output_path if output_path else 'æœªä¿å­˜'}")


def print_model_info():
    """
    æ‰“å°å¯ç”¨çš„YOLOæ¨¡å‹ä¿¡æ¯
    """
    models = {
        'yolov8n.pt': {'size': '6.2MB', 'mAP': '37.3', 'speed': '80+', 'description': 'Nano - æœ€å°ï¼Œæœ€å¿«'},
        'yolov8s.pt': {'size': '21.5MB', 'mAP': '44.9', 'speed': '50+', 'description': 'Small - é€Ÿåº¦å’Œç²¾åº¦å¹³è¡¡'},
        'yolov8m.pt': {'size': '49.7MB', 'mAP': '50.2', 'speed': '40+', 'description': 'Medium - è‰¯å¥½ç²¾åº¦'},
        'yolov8l.pt': {'size': '83.7MB', 'mAP': '52.9', 'speed': '30+', 'description': 'Large - é«˜ç²¾åº¦ï¼Œæ¨è'},
        'yolov8x.pt': {'size': '131.4MB', 'mAP': '53.9', 'speed': '20+', 'description': 'Extra Large - æœ€é«˜ç²¾åº¦ï¼Œæœ€æ…¢'},
    }

    print("\nå¯ç”¨çš„YOLOv8æ¨¡å‹:")
    print("-" * 80)
    print(f"{'æ¨¡å‹':<12} {'å¤§å°':<8} {'mAP':<6} {'FPS':<8} {'æè¿°'}")
    print("-" * 80)
    for model, info in models.items():
        print(f"{model:<12} {info['size']:<8} {info['mAP']:<6} {info['speed']:<8} {info['description']}")
    print("-" * 80)
    print("æ³¨æ„: æ›´å¤§çš„æ¨¡å‹ç²¾åº¦æ›´é«˜ä½†é€Ÿåº¦æ›´æ…¢")
    print("æ¨è: yolov8l.pt (é»˜è®¤) è¿½æ±‚é«˜ç²¾åº¦, yolov8s.pt è¿½æ±‚å¹³è¡¡æ€§èƒ½")


def get_model_choice():
    """
    è·å–ç”¨æˆ·çš„æ¨¡å‹é€‰æ‹©

    Returns:
        str: é€‰æ‹©çš„æ¨¡å‹è·¯å¾„æˆ–ç‰¹æ®Šæ ‡è¯†
    """
    print_model_info()

    print("\né€‰æ‹©YOLOæ¨¡å‹:")
    print("1. yolov8n.pt (Nano) - æœ€å¿«ï¼ŒåŸºç¡€ç²¾åº¦")
    print("2. yolov8s.pt (Small) - è‰¯å¥½çš„å¹³è¡¡æ€§èƒ½")
    print("3. yolov8m.pt (Medium) - ç²¾åº¦å’Œé€Ÿåº¦å¹³è¡¡")
    print("4. yolov8l.pt (Large) - ğŸ”¥ é»˜è®¤ - é«˜ç²¾åº¦ï¼Œæ¨è")
    print("5. yolov8x.pt (Extra Large) - æœ€é«˜ç²¾åº¦ï¼Œæœ€æ…¢")
    print("6. è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„")
    print("7. å¯¹æ¯”æ‰€æœ‰æ¨¡å‹ (æ€§èƒ½åŸºå‡†æµ‹è¯•)")

    while True:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-7, é»˜è®¤=4): ").strip()

        if not choice:
            return "yolov8l.pt"  # é»˜è®¤é€‰æ‹©
        elif choice == '1':
            return "yolov8n.pt"
        elif choice == '2':
            return "yolov8s.pt"
        elif choice == '3':
            return "yolov8m.pt"
        elif choice == '4':
            return "yolov8l.pt"
        elif choice == '5':
            return "yolov8x.pt"
        elif choice == '6':
            custom_path = input("è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„: ").strip()
            if custom_path:
                return custom_path
            else:
                print("è·¯å¾„æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤ yolov8s.pt")
                return "yolov8s.pt"
        elif choice == '7':
            return "COMPARE_ALL"
        else:
            print("æ— æ•ˆé€‰æ‹©ã€‚è¯·è¾“å…¥1-7ã€‚")


def compare_models(video_file):
    """
    å¯¹æ¯”ä¸åŒYOLOæ¨¡å‹çš„æ€§èƒ½

    Args:
        video_file (str): è§†é¢‘æ–‡ä»¶è·¯å¾„
    """
    models_to_test = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt']

    print(f"\n{'='*60}")
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print(f"{'='*60}")
    print(f"ä½¿ç”¨è§†é¢‘æ–‡ä»¶è¿›è¡Œæµ‹è¯•: {video_file}")
    print("å°†æµ‹è¯•æ¯ä¸ªæ¨¡å‹çš„å‰100å¸§è¿›è¡Œå¯¹æ¯”")
    print(f"{'='*60}")

    results = []

    for model_path in models_to_test:
        print(f"\næ­£åœ¨æµ‹è¯• {model_path}...")

        try:
            processor = VideoProcessor(model_path)

            # å¿«é€ŸåŸºå‡†æµ‹è¯• - åªæµ‹è¯•å‰100å¸§
            cap = cv2.VideoCapture(video_file)
            if not cap.isOpened():
                print(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_file}")
                continue

            fps = int(cap.get(cv2.CAP_PROP_FPS))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            test_frames = min(100, total_frames)

            start_time = time.time()
            frame_count = 0
            total_detections = 0

            while frame_count < test_frames:
                ret, frame = cap.read()
                if not ret:
                    break

                # æ£€æµ‹ç›®æ ‡
                detections = processor.detector.detect(frame)
                total_detections += len(detections)

                # æ›´æ–°è·Ÿè¸ªå™¨ï¼ˆä¸ºäº†é€Ÿåº¦ï¼Œä¸ç»˜åˆ¶ï¼‰
                processor.detector.tracker.update(detections)

                frame_count += 1

            cap.release()

            benchmark_time = time.time() - start_time
            avg_fps = frame_count / benchmark_time
            avg_detections = total_detections / max(frame_count, 1)

            results.append({
                'model': model_path,
                'fps': avg_fps,
                'detections': avg_detections,
                'time': benchmark_time
            })

            print(f"  âœ“ {model_path}: {avg_fps:.1f} FPS, {avg_detections:.1f} å¹³å‡æ£€æµ‹æ•°/å¸§")

        except Exception as e:
            print(f"  âœ— {model_path}: å¤±è´¥ - {e}")

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print(f"\n{'='*60}")
    print("åŸºå‡†æµ‹è¯•ç»“æœ")
    print(f"{'='*60}")
    print(f"{'æ¨¡å‹':<15} {'FPS':<8} {'å¹³å‡æ£€æµ‹':<10} {'æ—¶é—´(ç§’)':<10} {'è¯„çº§'}")
    print("-" * 60)

    for result in results:
        model = result['model']
        fps = result['fps']
        detections = result['detections']
        time_taken = result['time']

        if fps > 40:
            rating = "âš¡ æå¿«"
        elif fps > 25:
            rating = "âœ… è‰¯å¥½"
        elif fps > 15:
            rating = "âš ï¸  è¾ƒæ…¢"
        else:
            rating = "ğŸŒ å¾ˆæ…¢"

        print(f"{model:<15} {fps:<8.1f} {detections:<10.1f} {time_taken:<10.2f} {rating}")

    print("-" * 60)

    if results:
        fastest = max(results, key=lambda x: x['fps'])
        most_detect = max(results, key=lambda x: x['detections'])

        print(f"\nğŸ† æœ€å¿«æ¨¡å‹: {fastest['model']} ({fastest['fps']:.1f} FPS)")
        print(f"ğŸ¯ æ£€æµ‹æœ€å¤š: {most_detect['model']} ({most_detect['detections']:.1f} å¹³å‡)")

        # æ¨è
        avg_fps = sum(r['fps'] for r in results) / len(results)
        if avg_fps < 20:
            recommended = "yolov8n.pt (ä¼˜å…ˆé€Ÿåº¦)"
        elif avg_fps > 35:
            recommended = "yolov8l.pt æˆ– yolov8x.pt (ä¼˜å…ˆç²¾åº¦)"
        else:
            recommended = "yolov8s.pt æˆ– yolov8m.pt (å¹³è¡¡)"

        print(f"\nğŸ’¡ ä¸ºæ‚¨çš„ç³»ç»Ÿæ¨è: {recommended}")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("YOLO è½¦è¾†å’Œè¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿ")
    print("=" * 50)
    print("å¢å¼ºç‰ˆ - æ”¯æŒæ¨¡å‹é€‰æ‹©ä»¥è·å¾—æ›´é«˜ç²¾åº¦")

    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] in ['-h', '--help']:
            print("ç”¨æ³•: python detection_car.py [æ¨¡å‹è·¯å¾„]")
            print("ç¤ºä¾‹:")
            print("  python detection_car.py              # ä½¿ç”¨é»˜è®¤æ¨¡å‹ yolov8l.pt")
            print("  python detection_car.py yolov8s.pt   # ä½¿ç”¨æŒ‡å®šæ¨¡å‹")
            print("  python detection_car.py model.pt     # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹")
            return
        else:
            model_path = sys.argv[1]
            print(f"ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model_path}")
    else:
        # è·å–ç”¨æˆ·æ¨¡å‹é€‰æ‹©ï¼ˆå¦‚æœåœ¨äº¤äº’ç¯å¢ƒä¸­ï¼‰
        try:
            model_path = get_model_choice()
        except (EOFError, KeyboardInterrupt):
            # éäº¤äº’ç¯å¢ƒæˆ–ç”¨æˆ·ä¸­æ–­ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
            print("\næ£€æµ‹åˆ°éäº¤äº’ç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: yolov8l.pt")
            model_path = "yolov8l.pt"

    # æ£€æµ‹video.mp4æ–‡ä»¶
    video_file = "video.mp4"

    # å¤„ç†æ¨¡å‹å¯¹æ¯”é€‰é¡¹
    if model_path == "COMPARE_ALL":
        if not os.path.exists(video_file):
            print(f"\né”™è¯¯: æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ '{video_file}'!")
            print("è¯·åœ¨å½“å‰ç›®å½•ä¸‹æ”¾ç½® video.mp4 æ–‡ä»¶ã€‚")
            return

        compare_models(video_file)
        return

    # ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹åˆ›å»ºè§†é¢‘å¤„ç†å™¨
    processor = VideoProcessor(model_path)

    # åŸºäºæ¨¡å‹ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    model_name = os.path.basename(model_path).replace('.pt', '')
    output_file = f"output_{model_name}_result.mp4"

    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_file):
        print(f"\né”™è¯¯: æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ '{video_file}'!")
        print("è¯·åœ¨å½“å‰ç›®å½•ä¸‹æ”¾ç½® video.mp4 æ–‡ä»¶ã€‚")
        return

    # å¼€å§‹å¤„ç†
    print(f"\n{'='*50}")
    print(f"å¼€å§‹æ£€æµ‹ï¼Œé…ç½®ä¿¡æ¯:")
    print(f"  æ¨¡å‹: {model_path}")
    print(f"  è§†é¢‘: {video_file}")
    print(f"  è¾“å‡º: {output_file}")
    print(f"{'='*50}")
    print("æŒ‰ 'q' é€€å‡º, æŒ‰ 's' ä¿å­˜å½“å‰å¸§")
    print("æŒ‰ 'ESC' æˆ–å…³é—­çª—å£åœæ­¢å¤„ç†\n")

    processor.process_video(video_file, output_file, show_display=True)


if __name__ == "__main__":
    main()